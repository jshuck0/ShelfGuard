# src/analyst/orchestrator.py

"""
ORCHESTRATOR - The Agentic Brain (Layer 3)

This is the "Sherlock" that:
1. Plans which tools to use based on Profiler Vitals
2. Executes tools in the right order
3. Reads the structured Diagnostic Brief
4. Synthesizes strategic narratives via LLM

Architecture:
    Data → Profiler → Orchestrator → [Tools] → Brief → LLM → Narratives

The Orchestrator never sees raw data - only structured signals from tools.
"""

import os
import json
from dataclasses import dataclass, field
from typing import Dict, List, Optional, Any, Tuple
from datetime import datetime
import pandas as pd

from openai import OpenAI

from .config import KEEPA_CONFIG
from .profiler import run_profiler, ProfilerVitals
from .brief import (
    DiagnosticBrief, 
    build_diagnostic_brief, 
    MarketContext, 
    ProductIdentity
)
from .tools.calibrator import calibrate_physics, CalibratedPhysics
from .tools.volatility import detect_anomalies, AnomalySignal
from .tools.prediction import forecast_metrics, ForecastSignal
from .tools.causal import analyze_causality, CausalSignal
from .tools.cluster import segment_products, ClusterSignal


# =============================================================================
# PROMPTS
# =============================================================================

ANALYST_SYSTEM_PROMPT = """You are a Senior Amazon 3P Strategy Analyst with 15 years of experience.

Your job is to synthesize strategic narratives from diagnostic data. You receive structured 
briefs (not raw data) that have already been analyzed by specialized tools. Your role is to:

1. INTERPRET the signals and connect the dots across different analyses
2. GENERATE strategic narratives that explain WHAT happened and WHY
3. PREDICT likely outcomes and recommend actions
4. PRIORITIZE the 3 most important insights for the executive

RULES:
- You NEVER make up data. Every claim must be traceable to the diagnostic brief.
- You acknowledge uncertainty. If confidence is LOW, say so.
- You consider the PHYSICS of Amazon (from config): e.g., lower rank = better, not worse.
- You respect DIRECTIONALITY: A rank drop from 1000→500 is GOOD, not bad.
- You FILTER for RELEVANCE: Only discuss factors that affect the product category.
- You check FEASIBILITY: Don't recommend creating new products in 7 days.

OUTPUT FORMAT:
Generate exactly 3 strategic narratives, each with:
1. HEADLINE (10 words max)
2. SITUATION (What happened - 2 sentences)
3. CAUSE (Why it happened - reference the causal analysis)
4. PREDICTION (What will happen if this continues)
5. RECOMMENDATION (Specific action with expected impact)
6. CONFIDENCE (HIGH/MEDIUM/LOW with reasoning)

After the 3 narratives, provide:
- RED TEAM: What might you be wrong about?
- KEY METRICS TO WATCH: Top 3 metrics to monitor this week
"""

EDITOR_SYSTEM_PROMPT = """You are the Senior Editor reviewing analyst narratives.

Your job is to KILL bad ideas. Apply these 4 tests to each narrative:

1. RELEVANCE TEST: Does this strategy make sense for the product category?
   - A snack strategy for shampoo = KILL
   - A Valentine's Day gift set for deodorant = PASS (personal care gifting is real)

2. FEASIBILITY TEST: Can this be executed in 7 days with existing inventory?
   - "Launch new product line" = KILL
   - "Increase PPC spend by 20%" = PASS

3. SPECIFICITY TEST: Does this name specific products/competitors/numbers?
   - "Competitor is doing well" = KILL
   - "Native (ASIN B0...) dropped price 15%" = PASS

4. TONE TEST: Is this strategic or gimmicky?
   - "Snack-themed shampoo campaign" = KILL
   - "Counter-program competitor promotion" = PASS

For each narrative, output:
- VERDICT: PASS or KILL
- REASON: One sentence explaining why
- IF PASS: Any refinements needed

Only let through the TOP 3 narratives that pass all tests.
"""


# =============================================================================
# DATA CLASSES
# =============================================================================

@dataclass
class StrategicNarrative:
    """A single strategic narrative generated by the Analyst."""
    headline: str
    situation: str
    cause: str
    prediction: str
    recommendation: str
    confidence: str
    confidence_reasoning: str = ""
    narrative_type: str = "INSIGHT"  # OPPORTUNITY, THREAT, INSIGHT, WARNING
    expected_impact: Optional[float] = None
    urgency: str = "NORMAL"  # IMMEDIATE, THIS_WEEK, THIS_MONTH, NORMAL


@dataclass
class RedTeamAnalysis:
    """Adversarial analysis - what might be wrong?"""
    vulnerabilities: List[str] = field(default_factory=list)
    blind_spots: List[str] = field(default_factory=list)
    competitor_moves: List[str] = field(default_factory=list)


@dataclass
class OrchestratorOutput:
    """Complete output from the Orchestrator."""
    asin: str
    generated_at: str
    
    # The diagnostic brief used
    brief: Optional[DiagnosticBrief] = None
    
    # Generated narratives
    narratives: List[StrategicNarrative] = field(default_factory=list)
    
    # Red team analysis
    red_team: Optional[RedTeamAnalysis] = None
    
    # Key metrics to watch
    key_metrics: List[str] = field(default_factory=list)
    
    # Meta
    tokens_used: int = 0
    model_used: str = ""
    processing_time_seconds: float = 0.0
    
    # Errors
    errors: List[str] = field(default_factory=list)


# =============================================================================
# ORCHESTRATOR CLASS
# =============================================================================

class Orchestrator:
    """
    The Agentic Brain that coordinates all analysis.
    
    Implements the Observation → Thought → Action → Synthesis loop.
    """
    
    def __init__(self, openai_api_key: Optional[str] = None):
        """Initialize the Orchestrator with OpenAI client."""
        api_key = openai_api_key or os.getenv("OPENAI_API_KEY")
        if api_key:
            self.client = OpenAI(api_key=api_key)
        else:
            self.client = None
        
        self.model = "gpt-4o-mini"  # Default model
    
    def run(
        self,
        df_weekly: pd.DataFrame,
        asin: str = "UNKNOWN",
        product_info: Optional[Dict] = None,
        market_context: Optional[MarketContext] = None,
        journal_entries: Optional[List[Dict]] = None,
        df_summary: Optional[pd.DataFrame] = None,  # For clustering
        run_all_tools: bool = True
    ) -> OrchestratorOutput:
        """
        Main entry point: Run the complete analysis pipeline.
        
        Args:
            df_weekly: Weekly time series data for the product
            asin: ASIN identifier
            product_info: Product metadata (title, brand, category, etc.)
            market_context: External context (season, events, holidays)
            journal_entries: Past predictions from journal
            df_summary: Summary data for clustering (one row per product)
            run_all_tools: Whether to run all tools or just essentials
            
        Returns:
            OrchestratorOutput with narratives and analysis
        """
        start_time = datetime.now()
        output = OrchestratorOutput(
            asin=asin,
            generated_at=start_time.isoformat()
        )
        
        try:
            # STEP 1: Run Profiler (The Triage)
            profiler_vitals = run_profiler(df_weekly, asin)
            
            # STEP 2: Plan which tools to run based on vitals
            tool_plan = self._plan_tools(profiler_vitals, run_all_tools)
            
            # STEP 3: Execute tools
            tool_outputs = self._execute_tools(
                df_weekly, asin, tool_plan, df_summary
            )
            
            # STEP 4: Build Diagnostic Brief
            brief = build_diagnostic_brief(
                asin=asin,
                profiler_vitals=profiler_vitals,
                calibrated_physics=tool_outputs.get("calibrator"),
                anomaly_signal=tool_outputs.get("volatility"),
                forecast_signal=tool_outputs.get("prediction"),
                causal_signal=tool_outputs.get("causal"),
                cluster_signal=tool_outputs.get("cluster"),
                product_info=product_info,
                market_context=market_context,
                journal_entries=journal_entries
            )
            output.brief = brief
            
            # STEP 5: Generate narratives via LLM
            if self.client:
                narratives, red_team, key_metrics, tokens = self._synthesize_narratives(brief)
                output.narratives = narratives
                output.red_team = red_team
                output.key_metrics = key_metrics
                output.tokens_used = tokens
                output.model_used = self.model
            else:
                output.errors.append("NO_OPENAI_CLIENT")
            
        except Exception as e:
            output.errors.append(f"ORCHESTRATOR_ERROR: {str(e)}")
        
        output.processing_time_seconds = (datetime.now() - start_time).total_seconds()
        return output
    
    def _plan_tools(
        self, 
        vitals: ProfilerVitals, 
        run_all: bool
    ) -> Dict[str, bool]:
        """
        Plan which tools to run based on Profiler vitals.
        
        This is the "Thought" step of the agentic loop.
        """
        plan = {
            "calibrator": True,  # Always calibrate physics
            "volatility": True,  # Always check for anomalies
            "prediction": True,  # Always forecast
            "causal": False,     # Only if enough data
            "cluster": False,    # Only if multiple products
        }
        
        if run_all:
            plan["causal"] = True
            plan["cluster"] = True
            return plan
        
        # Intelligent planning based on vitals
        if vitals.data_health.total_weeks >= 8:
            plan["causal"] = True
        
        if vitals.overall_health in ["CRITICAL", "AT_RISK"]:
            plan["causal"] = True  # Need to understand why
        
        return plan
    
    def _execute_tools(
        self,
        df_weekly: pd.DataFrame,
        asin: str,
        plan: Dict[str, bool],
        df_summary: Optional[pd.DataFrame] = None
    ) -> Dict[str, Any]:
        """
        Execute the planned tools.
        
        This is the "Action" step of the agentic loop.
        """
        outputs = {}
        
        if plan.get("calibrator"):
            outputs["calibrator"] = calibrate_physics(df_weekly, asin)
        
        if plan.get("volatility"):
            outputs["volatility"] = detect_anomalies(df_weekly, asin)
        
        if plan.get("prediction"):
            outputs["prediction"] = forecast_metrics(df_weekly, asin)
        
        if plan.get("causal"):
            outputs["causal"] = analyze_causality(df_weekly, asin)
        
        if plan.get("cluster") and df_summary is not None:
            outputs["cluster"] = segment_products(df_summary, asin)
        
        return outputs
    
    def _synthesize_narratives(
        self, 
        brief: DiagnosticBrief
    ) -> Tuple[List[StrategicNarrative], RedTeamAnalysis, List[str], int]:
        """
        Generate strategic narratives from the Diagnostic Brief.
        
        This is the "Synthesis" step - the LLM's primary job.
        """
        # Build the prompt
        prompt = brief.to_prompt_string()
        
        # Call LLM
        response = self.client.chat.completions.create(
            model=self.model,
            messages=[
                {"role": "system", "content": ANALYST_SYSTEM_PROMPT},
                {"role": "user", "content": f"Analyze this diagnostic brief and generate strategic narratives:\n\n{prompt}"}
            ],
            temperature=0.7,
            max_tokens=2000
        )
        
        raw_output = response.choices[0].message.content
        tokens_used = response.usage.total_tokens if response.usage else 0
        
        # Parse the response
        narratives = self._parse_narratives(raw_output)
        
        # Run Editor pass to filter narratives
        if len(narratives) > 0:
            narratives = self._run_editor_pass(narratives, brief)
        
        # Extract red team and key metrics
        red_team = self._parse_red_team(raw_output)
        key_metrics = self._parse_key_metrics(raw_output)
        
        return narratives, red_team, key_metrics, tokens_used
    
    def _run_editor_pass(
        self, 
        narratives: List[StrategicNarrative],
        brief: DiagnosticBrief
    ) -> List[StrategicNarrative]:
        """
        Run the Editor to filter out bad narratives.
        
        Applies the 4 kill-tests: Relevance, Feasibility, Specificity, Tone.
        """
        if not self.client or len(narratives) == 0:
            return narratives
        
        # Build editor prompt
        narrative_text = "\n\n".join([
            f"NARRATIVE {i+1}:\n"
            f"Headline: {n.headline}\n"
            f"Situation: {n.situation}\n"
            f"Recommendation: {n.recommendation}"
            for i, n in enumerate(narratives)
        ])
        
        context = f"""
Product Category: {brief.product_identity.category}
Brand: {brief.product_identity.brand}
Price Tier: {brief.product_identity.price_tier}

NARRATIVES TO REVIEW:
{narrative_text}
"""
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": EDITOR_SYSTEM_PROMPT},
                    {"role": "user", "content": context}
                ],
                temperature=0.3,  # More deterministic for editing
                max_tokens=1000
            )
            
            editor_output = response.choices[0].message.content
            
            # Parse which narratives passed
            passed_indices = self._parse_editor_output(editor_output, len(narratives))
            
            # Filter narratives
            return [narratives[i] for i in passed_indices if i < len(narratives)]
            
        except Exception:
            # If editor fails, return top 3 as-is
            return narratives[:3]
    
    def _parse_narratives(self, raw_output: str) -> List[StrategicNarrative]:
        """Parse LLM output into StrategicNarrative objects."""
        narratives = []
        
        # Split by narrative markers
        sections = raw_output.split("HEADLINE")
        
        for section in sections[1:]:  # Skip first empty section
            try:
                narrative = StrategicNarrative(
                    headline=self._extract_field(section, "HEADLINE", "SITUATION"),
                    situation=self._extract_field(section, "SITUATION", "CAUSE"),
                    cause=self._extract_field(section, "CAUSE", "PREDICTION"),
                    prediction=self._extract_field(section, "PREDICTION", "RECOMMENDATION"),
                    recommendation=self._extract_field(section, "RECOMMENDATION", "CONFIDENCE"),
                    confidence=self._extract_field(section, "CONFIDENCE", None),
                )
                
                # Classify narrative type
                if any(word in narrative.headline.lower() for word in ["opportunity", "growth", "upside"]):
                    narrative.narrative_type = "OPPORTUNITY"
                elif any(word in narrative.headline.lower() for word in ["threat", "risk", "warning", "decline"]):
                    narrative.narrative_type = "THREAT"
                
                narratives.append(narrative)
            except:
                continue
        
        return narratives
    
    def _extract_field(
        self, 
        text: str, 
        start_marker: str, 
        end_marker: Optional[str]
    ) -> str:
        """Extract a field from the LLM output."""
        text = text.replace(f"{start_marker}:", "").replace(f"{start_marker}", "")
        
        if end_marker:
            parts = text.split(end_marker)
            return parts[0].strip() if parts else ""
        
        # Get first line/paragraph
        lines = text.strip().split("\n")
        return lines[0].strip() if lines else ""
    
    def _parse_red_team(self, raw_output: str) -> RedTeamAnalysis:
        """Parse red team analysis from LLM output."""
        red_team = RedTeamAnalysis()
        
        if "RED TEAM" in raw_output:
            red_section = raw_output.split("RED TEAM")[-1].split("KEY METRICS")[0]
            lines = [l.strip() for l in red_section.split("\n") if l.strip() and l.strip().startswith("-")]
            red_team.vulnerabilities = lines[:3]
        
        return red_team
    
    def _parse_key_metrics(self, raw_output: str) -> List[str]:
        """Parse key metrics from LLM output."""
        metrics = []
        
        if "KEY METRICS" in raw_output:
            metrics_section = raw_output.split("KEY METRICS")[-1]
            lines = [l.strip() for l in metrics_section.split("\n") if l.strip() and l.strip().startswith("-")]
            metrics = [l.lstrip("- ").strip() for l in lines[:3]]
        
        return metrics
    
    def _parse_editor_output(self, editor_output: str, total_narratives: int) -> List[int]:
        """Parse which narratives the editor passed."""
        passed = []
        
        for i in range(total_narratives):
            # Look for "NARRATIVE X: PASS" patterns
            if f"NARRATIVE {i+1}" in editor_output.upper():
                section = editor_output.upper().split(f"NARRATIVE {i+1}")[-1].split("NARRATIVE")[0]
                if "PASS" in section and "KILL" not in section.split("PASS")[0]:
                    passed.append(i)
        
        # If parsing fails, return first 3
        if not passed:
            return list(range(min(3, total_narratives)))
        
        return passed[:3]


# =============================================================================
# CONVENIENCE FUNCTIONS
# =============================================================================

def run_sherlock_analysis(
    df_weekly: pd.DataFrame,
    asin: str = "UNKNOWN",
    product_info: Optional[Dict] = None,
    market_context: Optional[MarketContext] = None,
    journal_entries: Optional[List[Dict]] = None,
    df_summary: Optional[pd.DataFrame] = None,
    openai_api_key: Optional[str] = None
) -> OrchestratorOutput:
    """
    Convenience function to run the complete Sherlock analysis.
    
    This is the main entry point for external code.
    """
    orchestrator = Orchestrator(openai_api_key=openai_api_key)
    return orchestrator.run(
        df_weekly=df_weekly,
        asin=asin,
        product_info=product_info,
        market_context=market_context,
        journal_entries=journal_entries,
        df_summary=df_summary,
        run_all_tools=True
    )


def get_quick_vitals(df_weekly: pd.DataFrame, asin: str = "UNKNOWN") -> Dict[str, Any]:
    """
    Quick health check without full analysis.
    
    Returns essential vitals without running the full pipeline.
    """
    vitals = run_profiler(df_weekly, asin)
    physics = calibrate_physics(df_weekly, asin)
    
    return {
        "health": vitals.overall_health,
        "confidence": vitals.confidence_score,
        "trends": {k: v.direction for k, v in vitals.trends.items()},
        "alerts": vitals.critical_alerts,
        "physics": physics.to_dict() if physics else None,
    }
